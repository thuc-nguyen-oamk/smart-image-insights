{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z3a1mrCSQfZ"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "\n",
        "# Suppress warning messages from Transformers library\n",
        "transformers.logging.set_verbosity_error()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a Question-Answering Pipeline\n"
      ],
      "metadata": {
        "id": "SIAnqmiFShVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Define the context for the question-answering task\n",
        "context_text = \"\"\"\n",
        "Earth is the third planet from the Sun and the only astronomical object\n",
        "known to harbor life. While large volumes of water can be found\n",
        "throughout the Solar System, only Earth sustains liquid surface water.\n",
        "About 71% of Earth's surface is made up of the ocean, dwarfing\n",
        "Earth's polar ice, lakes, and rivers. The remaining 29% of Earth's\n",
        "surface is land, consisting of continents and islands.\n",
        "Earth's surface layer is formed of several slowly moving tectonic plates,\n",
        "interacting to produce mountain ranges, volcanoes, and earthquakes.\n",
        "Earth's liquid outer core generates the magnetic field that shapes Earth's\n",
        "magnetosphere, deflecting destructive solar winds.\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the question-answering pipeline with a pretrained model\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/minilm-uncased-squad2\")\n",
        "\n",
        "# Ask a question and get the answer from the pipeline\n",
        "question_1 = \"How much of Earth is land?\"\n",
        "response_1 = qa_pipeline(question=question_1, context=context_text)\n",
        "print(response_1)\n"
      ],
      "metadata": {
        "id": "1qjMgbZhSUWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask another question and display the response\n",
        "question_2 = \"How are mountain ranges created?\"\n",
        "response_2 = qa_pipeline(question=question_2, context=context_text)\n",
        "\n",
        "print(\"\\nAnother question:\")\n",
        "print(response_2)\n"
      ],
      "metadata": {
        "id": "KHWqJuRHSYvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Question-Answering Performance\n"
      ],
      "metadata": {
        "id": "uHmP4XRrSeNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "# Load the SQuAD evaluation metric\n",
        "squad_evaluator = load(\"squad_v2\")\n",
        "\n",
        "# Define the correct answer for evaluation\n",
        "expected_answer = \"Paris\"\n",
        "\n",
        "# Define a list of predicted answers for evaluation\n",
        "predicted_answers_list = [\n",
        "    \"Paris\",\n",
        "    \"London\",\n",
        "    \"Paris is one of the best cities in the world\"\n",
        "]\n",
        "\n",
        "# Initialize cumulative predictions and references for evaluation\n",
        "cumulative_predictions = []\n",
        "cumulative_references = []\n",
        "\n",
        "# Evaluate each predicted answer\n",
        "for index, predicted_answer in enumerate(predicted_answers_list):\n",
        "    # Format predictions for evaluation\n",
        "    formatted_prediction = [{\n",
        "        'prediction_text': predicted_answer,\n",
        "        'id': str(index),\n",
        "        'no_answer_probability': 0.0\n",
        "    }]\n",
        "    cumulative_predictions.append(formatted_prediction[0])\n",
        "\n",
        "    # Format references for evaluation\n",
        "    formatted_reference = [{\n",
        "        'answers': {\n",
        "            'answer_start': [1],\n",
        "            'text': [expected_answer]\n",
        "        },\n",
        "        'id': str(index)\n",
        "    }]\n",
        "    cumulative_references.append(formatted_reference[0])\n",
        "\n",
        "    # Compute evaluation results for the current prediction\n",
        "    individual_results = squad_evaluator.compute(\n",
        "        predictions=formatted_prediction,\n",
        "        references=formatted_reference\n",
        "    )\n",
        "    print(f\"F1 Score: {individual_results['f1']} for prediction: {predicted_answer}\")\n",
        "\n",
        "# Compute cumulative evaluation results\n",
        "overall_results = squad_evaluator.compute(\n",
        "    predictions=cumulative_predictions,\n",
        "    references=cumulative_references\n",
        ")\n",
        "print(\"\\nCumulative Results:\\n\", overall_results)\n"
      ],
      "metadata": {
        "id": "kWyLP_XUSogC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}